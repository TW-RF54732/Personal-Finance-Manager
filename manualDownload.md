
# ğŸ› ï¸ æ‰‹å‹•å®‰è£èˆ‡ç’°å¢ƒé…ç½®æŒ‡å— (Manual Setup)

æœ¬æŒ‡å—é©ç”¨æ–¼æƒ³è¦åœ¨æœ¬åœ°ç’°å¢ƒ (Host Machine) ç›´æ¥é‹è¡Œ FinBase çš„é–‹ç™¼è€…ã€‚
æœ¬å°ˆæ¡ˆé‡å° **Windows 11** èˆ‡ **Python 3.11.9** å„ªåŒ–ï¼Œä½†äº¦å¯åœ¨ Linux/MacOS ä¸Šé‹è¡Œã€‚

## âš ï¸ å‰ç½®æ³¨æ„äº‹é …

1. **Python ç‰ˆæœ¬**ï¼šå¼·çƒˆå»ºè­°ä½¿ç”¨ **Python 3.11.x**ã€‚
* `llama-cpp-python` çš„é ç·¨è­¯ Wheel æª”å° Python ç‰ˆæœ¬éå¸¸æ•æ„Ÿï¼Œä½¿ç”¨ 3.12+ æˆ– 3.10- å¯èƒ½æœƒæ‰¾ä¸åˆ°å°æ‡‰çš„å®‰è£æª”ã€‚


2. **C++ ç·¨è­¯ç’°å¢ƒ (åƒ… GPU æ¨¡å¼éœ€è¦)**ï¼š
* Windows ç”¨æˆ¶è‹¥è¦è‡ªè¡Œç·¨è­¯ GPU ç‰ˆæœ¬ï¼Œéœ€å®‰è£ **Visual Studio Community** (å‹¾é¸ "ä½¿ç”¨ C++ çš„æ¡Œé¢é–‹ç™¼")ã€‚
* è‹¥ä½¿ç”¨æˆ‘å€‘æä¾›çš„é ç·¨è­¯æŒ‡ä»¤ï¼Œå‰‡åªéœ€å®‰è£ **CUDA Toolkit**ã€‚



---

## æ­¥é©Ÿ 1ï¼šç’°å¢ƒæº–å‚™

### 1. æª¢æŸ¥ Python ç‰ˆæœ¬

é–‹å•Ÿçµ‚ç«¯æ©Ÿ (PowerShell æˆ– CMD)ï¼Œç¢ºèªç‰ˆæœ¬ç‚º 3.11 ç³»åˆ—ï¼š

```powershell
python --version
# è¼¸å‡ºæ‡‰ç‚º Python 3.11.x
# è‹¥æœªå®‰è£ï¼Œè«‹è‡³ Python å®˜ç¶²ä¸‹è¼‰ 3.11.9 ç‰ˆæœ¬

```

### 2. ä¸‹è¼‰å°ˆæ¡ˆ

```powershell
git clone https://github.com/TW-RF54732/Personal-Finance-Manager.git
cd Personal-Finance-Manager

```

---

## æ­¥é©Ÿ 2ï¼šå»ºç«‹è™›æ“¬ç’°å¢ƒ (Virtual Environment)

ç‚ºäº†é¿å…èˆ‡ç³»çµ±å…¶ä»–å°ˆæ¡ˆçš„ä¾è³´è¡çªï¼Œ**å¼·çƒˆå»ºè­°**ä½¿ç”¨è™›æ“¬ç’°å¢ƒã€‚

```powershell
# 1. å»ºç«‹åç‚º .venv çš„è™›æ“¬ç’°å¢ƒ
python -m venv .venv

# 2. å•Ÿå‹•è™›æ“¬ç’°å¢ƒ
# Windows PowerShell:
.\.venv\Scripts\Activate.ps1
# Linux / Mac:
# source .venv/bin/activate

```

> [!TIP]
> **Windows ç”¨æˆ¶å¸¸è¦‹éŒ¯èª¤**ï¼š
> è‹¥åŸ·è¡Œ Activate æ™‚å‡ºç¾ã€Œå› ç‚ºé€™å€‹ç³»çµ±ä¸Šå·²åœç”¨æŒ‡ä»¤ç¢¼åŸ·è¡Œ...ã€ï¼Œè«‹ä»¥ç®¡ç†å“¡èº«åˆ†åŸ·è¡Œ PowerShell ä¸¦è¼¸å…¥ï¼š
> `Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope Process`

---

## æ­¥é©Ÿ 3ï¼šå®‰è£ä¾è³´å¥—ä»¶

è«‹æ ¹æ“šæ‚¨çš„ç¡¬é«”è¨­å‚™é¸æ“‡ **CPU æ¨¡å¼** æˆ– **GPU æ¨¡å¼** (äºŒé¸ä¸€)ã€‚

###  é¸é … Aï¼šCPU æ¨¡å¼ (ç›¸å®¹æ€§æœ€é«˜)

è‹¥æ‚¨æ²’æœ‰ NVIDIA é¡¯å¡ï¼Œæˆ–ä¸æƒ³è¨­å®š CUDA ç’°å¢ƒï¼Œè«‹ä½¿ç”¨æ­¤æ¨¡å¼ã€‚

```powershell
# å‡ç´š pip
python -m pip install --upgrade pip

# å®‰è£ä¾è³´
# requirements.txt å·²åŒ…å«æŒ‡å‘ CPU ç‰ˆæœ¬çš„ extra-index-url
pip install -r requirements.txt

```

### é¸é … Bï¼šNVIDIA GPU åŠ é€Ÿæ¨¡å¼

è‹¥æ‚¨æœ‰ NVIDIA é¡¯å¡ä¸”å·²å®‰è£ [CUDA Toolkit 12.x](https://developer.nvidia.com/cuda-downloads)ã€‚

**é—œéµæ­¥é©Ÿ**ï¼šå¿…é ˆå¼·åˆ¶æŒ‡å®šå®‰è£æ”¯æ´ CUDA çš„ `llama-cpp-python` ç‰ˆæœ¬ã€‚

```powershell
# 1. å‡ç´š pip
python -m pip install --upgrade pip

# 2. å®‰è£åŸºæœ¬ä¾è³´ (æ’é™¤ llama-cpp-pythonï¼Œé¿å…è£æˆ CPU ç‰ˆ)
# å…ˆç”¢ç”Ÿä¸å« llama-cpp çš„æš«å­˜æ¸…å–®
Get-Content requirements.txt | Select-String -Pattern "llama-cpp-python" -NotMatch > req_base.txt
pip install -r req_base.txt
# è¨˜å¾—å®‰è£ huggingface å·¥å…·
pip install huggingface_hub[cl]

# 3. å®‰è£æ”¯æ´ CUDA 12 çš„ llama-cpp-python
# æ³¨æ„ï¼šé€™è£¡å¼·åˆ¶ä½¿ç”¨é ç·¨è­¯çš„ CUDA 12 Wheel æª”
pip install llama-cpp-python==0.2.90 --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu121 --force-reinstall --no-cache-dir

```

> [!NOTE]
> * è‹¥æ‚¨çš„ CUDA ç‰ˆæœ¬ç‚º 11.xï¼Œè«‹å°‡ç¶²å€ä¸­çš„ `cu121` æ”¹ç‚º `cu117`ã€‚
> * é©—è­‰å®‰è£ï¼šè¼¸å…¥ `python -c "import llama_cpp; print('GPU Lib Loaded')"` è‹¥ç„¡å ±éŒ¯å³æˆåŠŸã€‚
> 
> 

---

## æ­¥é©Ÿ 4ï¼šè³‡æ–™å¤¾èˆ‡æ¨¡å‹é…ç½®

ç”±æ–¼æ‰‹å‹•å®‰è£ä¸æœƒè‡ªå‹•åŸ·è¡Œ Docker çš„ `entrypoint.sh`ï¼Œæ‚¨éœ€è¦æ‰‹å‹•å»ºç«‹è³‡æ–™å¤¾çµæ§‹ã€‚

### 1. å»ºç«‹ç›®éŒ„

åœ¨å°ˆæ¡ˆæ ¹ç›®éŒ„ä¸‹åŸ·è¡Œï¼š

```powershell
mkdir data
mkdir data\DB
mkdir data\models

```

### 2. ä¸‹è¼‰æ¨¡å‹ (GGUF æ ¼å¼)

æœ¬å°ˆæ¡ˆé è¨­æ”¯æ´ **Llama-3-Taiwan-8B-Instruct**ã€‚

* 
**ä¸‹è¼‰é€£çµ**ï¼š[HuggingFace - Llama-3-Taiwan-8B-Instruct-GGUF](https://huggingface.co/chienweichang/Llama-3-Taiwan-8B-Instruct-GGUF/tree/main) 


* 
**æ¨è–¦æª”æ¡ˆ**ï¼š`llama-3-taiwan-8B-instruct-q5_k_m.gguf` (å…¼é¡§é€Ÿåº¦èˆ‡å“è³ª) 


* **å­˜æ”¾ä½ç½®**ï¼šå°‡ä¸‹è¼‰çš„ `.gguf` æª”æ¡ˆæ”¾å…¥ `data\models\` è³‡æ–™å¤¾ä¸­ã€‚

### 3. (é€²éš) ä½¿ç”¨ Python è‡ªå‹•ä¸‹è¼‰

å¦‚æœæ‚¨å·²å®‰è£ `huggingface_hub`ï¼Œä¹Ÿå¯ä»¥åŸ·è¡Œä»¥ä¸‹ Python æŒ‡ä»¤è‡ªå‹•ä¸‹è¼‰ï¼š

```python
from huggingface_hub import hf_hub_download
hf_hub_download(
    repo_id="chienweichang/Llama-3-Taiwan-8B-Instruct-GGUF",
    filename="llama-3-taiwan-8B-instruct-q5_k_m.gguf",
    local_dir="./data/models",
    local_dir_use_symlinks=False
)

```

---

## æ­¥é©Ÿ 5ï¼šä¿®æ”¹è¨­å®šæª”

è«‹é–‹å•Ÿ `data/config.py` (æˆ– `settings.json` è‹¥æ‚¨å·²å•Ÿç”¨å‹•æ…‹è¨­å®š)ï¼Œç¢ºä¿æ¨¡å‹è·¯å¾‘æŒ‡å‘æ‚¨çš„æœ¬åœ°è·¯å¾‘ã€‚

**æ³¨æ„**ï¼šDocker ç’°å¢ƒçš„è·¯å¾‘æ˜¯ `/app/data/...`ï¼Œæ‰‹å‹•åŸ·è¡Œæ™‚è«‹æ”¹ç‚ºç›¸å°è·¯å¾‘ã€‚

```python
# ä¿®æ”¹å‰ (Docker è·¯å¾‘)
# LLM_model_path = "/app/data/models/llama-3-taiwan-8B-instruct-q5_k_m.gguf"

# ä¿®æ”¹å¾Œ (æœ¬åœ°ç›¸å°è·¯å¾‘)
LLM_model_path = "./data/models/llama-3-taiwan-8B-instruct-q5_k_m.gguf"

```

---

## æ­¥é©Ÿ 6ï¼šå•Ÿå‹•æœå‹™

å®Œæˆä»¥ä¸Šæ­¥é©Ÿå¾Œï¼Œå³å¯å•Ÿå‹•å¾Œç«¯ä¼ºæœå™¨ã€‚

```powershell
# ä½¿ç”¨ uvicorn å•Ÿå‹•
# --reload: ç¨‹å¼ç¢¼è®Šæ›´æ™‚è‡ªå‹•é‡å•Ÿ (é–‹ç™¼æ¨¡å¼)
uvicorn app:app --host 0.0.0.0 --port 8000 --reload

```

å•Ÿå‹•æˆåŠŸå¾Œï¼Œè«‹ç€è¦½å™¨æ‰“é–‹ï¼š

* **API æ–‡ä»¶ (Swagger UI)**: `http://127.0.0.1:8000/docs`

---

## â“ å¸¸è¦‹å•é¡Œæ’é™¤

1. **ImportError: DLL load failed while importing llama_cpp**
* **åŸå› **ï¼šç¼ºå°‘ Visual C++ Redistributable æˆ– CUDA ç‰ˆæœ¬ä¸åŒ¹é…ã€‚
* **è§£æ³•**ï¼š
* å®‰è£æœ€æ–°ç‰ˆ [Visual C++ Redistributable](https://learn.microsoft.com/en-us/cpp/windows/latest-supported-vc-redist)ã€‚
* ç¢ºèªå®‰è£çš„ `llama-cpp-python` ç‰ˆæœ¬ (cu121/cu117) èˆ‡ç³»çµ± `nvidia-smi` é¡¯ç¤ºçš„ CUDA ç‰ˆæœ¬ç›¸å®¹ã€‚




2. **è¨˜æ†¶é«”ä¸è¶³ (OOM)**
* **åŸå› **ï¼šæ¨¡å‹æª”æ¡ˆå¤ªå¤§æˆ– RAM/VRAM ä¸è¶³ã€‚
* **è§£æ³•**ï¼šè«‹æ”¹ä¸‹è¼‰ `Q4_K_M.gguf` ç‰ˆæœ¬ (æª”æ¡ˆè¼ƒå°)ï¼Œæˆ–åœ¨ `config.py` ä¸­èª¿æ•´ `n_gpu_layers` åƒæ•¸ (è¨­ç‚º 0 æ”¹ç”¨ç´” CPU è·‘è·‘çœ‹)ã€‚
